{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Twitter_Guncel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Tweet Function\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(r'@[A-Za-z0-9]+', ' ', tweet) # Removing @mentions\n",
    "    tweet = re.sub(r'#', '', tweet) # Removing '#' hash tag\n",
    "    tweet = re.sub(r'RT[\\s]+', '', tweet) # Removing RT\n",
    "    tweet = re.sub(r'https?:\\/\\/\\S+', '', tweet) # Removing hyperlink\n",
    "    tweet = re.sub(r'&amp;', ' ', tweet) # Removing &amp;\n",
    "    tweet = re.sub(r'&gt;', ' ', tweet) # Removing &gt;\n",
    "    tweet = re.sub(r'&lt;', ' ', tweet) # Removing &lt;\n",
    "    tweet = re.sub(r'&quot;', ' ', tweet) # Removing &quot;\n",
    "    tweet = re.sub(r'&apos;', ' ', tweet) # Removing &apos;\n",
    "    tweet = re.sub(r'&nbsp;', ' ', tweet) # Removing &nbsp;\n",
    "    tweet = re.sub(r'&iexcl;', ' ', tweet) # Removing &iexcl;\n",
    "    # clean links such as https://t.co/Tu3oE2zQ1Q\n",
    "    tweet = re.sub(r'https://t.co/[A-Za-z0-9]+', ' ', tweet)\n",
    "    return tweet\n",
    "\n",
    "    \n",
    "# apply on column\n",
    "df['contents'] = df['contents'].apply(clean_tweet)\n",
    "# clean \\n from contents\n",
    "df['contents'] = df['contents'].str.replace(r'\\n', ' ')\n",
    "# replace / with space\n",
    "df['contents'] = df['contents'].str.replace(r'/', ' ')\n",
    "# replace \\ with space\n",
    "df['contents'] = df['contents'].str.replace(r'\\\\', ' ')\n",
    "\n",
    "df['contents'] = df['contents'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace , with space\n",
    "df['contents'] = df['contents'].str.replace(r',', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename contents as adres\n",
    "df.rename(columns={'contents':'adres'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf = pd.read_excel('sehıler.xlsx')\n",
    "qf.columns= ['1','il','ilce']\n",
    "city = ['adana', 'adıyaman', 'batman', 'bingöl', 'bingol','bitlis', 'diyarbakır', 'elazığ', 'gaziantep', 'hakkari', 'hatay', 'kahramanmaraş', 'kilis', 'malatya', 'mardin', 'mersin', 'osmaniye', 'şanlıurfa','adiyaman','sanliurfa']\n",
    "qf['il'] = qf['il'].str.lower()\n",
    "check = qf[qf['il'].isin(city)]['ilce'].unique().tolist()\n",
    "check = [word.lower() for word in check]\n",
    "#  find items that is present in check but not in city\n",
    "# x = [item for item in check if item not in city]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renmae contents as adres\n",
    "df.rename(columns={'contents':'adres'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search citys such as gaziantep adana malatya and put all into another column use join\n",
    "df['deprem'] = df['adres'].str.findall('|'.join(city)).astype(str)\n",
    "df['deprem'] = df['deprem'].str.replace('[','').str.replace(']','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "il = qf['il'].unique().tolist()\n",
    "iller = list(set(il) - set(city))\n",
    "# Deprem olmayan iller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yardım gelen iller, diğer iller.\n",
    "df['Gelen'] = df['adres'].str.findall('|'.join(iller)).astype(str)\n",
    "df['Gelen'] = df['Gelen'].str.replace('[','').str.replace(']','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinma_keywords = [\"soguktan\",\"usuyoruz\",\"donmak\",\"soguk\",\"soguk deprem\",\"hava soguk yardim edin\",\n",
    "                   \"hipotermi\",\"deprem battaniye\",\"isinmak istiyoruz\",\"donacagiz\",\"deprem eldiven\",\n",
    "                   \"deprem kaban\",\"deprem mont\",\"deprem tup\",\"deprem cadir\",\"cadir istiyoruz\",\n",
    "                   \"soguktan olecegiz\",\"soguktan olecegiz yardim edin\",\"isinacak yerimiz yok\",\n",
    "                   \"isinmaliyiz\",\"kalacak yer\",\"kalacak yerimiz yok\",\"titriyoruz\",\"deprem titriyoruz\",\n",
    "                   \"acil soguktan\",\"acil kalacak yer\",\"acil isinma yardim\",\"acil battaniye\",\"acil kiyafet\",\n",
    "                   \"acil yatak\"]\n",
    "\n",
    "barinma_keywords = [\"barinma yardim\",\"cadir yardim\",\"cadir\",\"cadir istiyoruz\",\"soguk\",\"soguktan olecegiz\",\n",
    "                    \"kalacak yer\",\"usuyoruz\",\"donuyoruz\",\"olmek uzereyiz\",\"isinmak istiyoruz\",\"soguktan olmek\",\n",
    "                    \"hipotermi\",\"siginma alani\",\"cadir talebi\",\"barinma talebi\",\"cadirimiz yok\",\"cocuklar usuyor\",\n",
    "                    \"ailem usuyor\",\"disaridayiz\",\"hava soguk\",\"soguk\",\"soguktan usuyoruz\",\"evim yok\",\"evimiz yok\",\n",
    "                    \"cadir bulamiyoruz\",\"aracta kaliyoruz\",\"arabada kaliyoruz\",\"sokaktayiz\"\n",
    "                    \"soguktan\",\"usuyoruz\",\"donmak\",\"soguk deprem\",\"hava soguk yardim edin\",\n",
    "                    \"hipotermi\",\"deprem battaniye\",\"isinmak istiyoruz\",\"donacagiz\",\"deprem eldiven\",\n",
    "                    \"deprem kaban\",\"deprem mont\",\"deprem tup\",\"deprem cadir\",\"cadir istiyoruz\",\"donarak\",\n",
    "                    \"soguktan olecegiz yardim edin\",\"isinacak yerimiz yok\",\n",
    "                    \"isinmaliyiz\",\"kalacak yerimiz yok\",\"titriyoruz\",\"deprem titriyoruz\",\n",
    "                    \"acil soguktan\",\"acil kalacak yer\",\"acil isinma yardim\",\"acil battaniye\",\"acil kiyafet\",\n",
    "                    \"acil yatak\",\"soğuk\",\"kalacak yer\"]\n",
    "\n",
    "barınma_keywords = [\"barinma\",\"barinma istiyoruz\", \"acil barinma yardim edin\", \"çadır\", \"konteyner\", \"ailem usuyor\",\"soguktan olecegiz\",\"çadır\",\"disaridayiz\",\"arabada kaliyoruz\"] \n",
    "\n",
    "yemek_keywords = [\"yemek\", \"yemek istiyoruz\", \"yemek yardim edin\", \"acil yemek yardim edin\",\"gıda\",\"konserve\",\"açlık\",\"açlıktan\",\"açlıktan öleceğiz\",\"açız\",\"erzak\",\"süt\"]\n",
    "\n",
    "su_keywords = [\"su\", \"su istiyoruz\", \"su yardim edin\", \"acil su yardim edin\",\"su lazım, sıvı lazım\"]\n",
    "\n",
    "yagma = [ \"suriyeliler\",'çaldılar' ,'talan', 'yagma', \"yağmalandı\",\"saldırıyor\",\"yağma\",\"gasp\", \"kapışılıyor\", \"hırsızlık\", \"çalma\", \"soygun\",\"tır yağmalanıyor\",\"tıra saldırıyorlar\", \"yağmalanıyor\",\"kaos\"]\n",
    "\n",
    "tuvalet_keywords = [\"tuvalet\", \"tuvalet\"]\n",
    "\n",
    "giysi_keywords = [\"giysi talebi\", \"giysi\", \"battaniye\", \"yagmurluk\", \"kazak\", \"corap\", \"soguk\", \"bot\", \"isitici\", \"cadir\", \"hava\", \n",
    "                    \"camasir\", \"pijama\", \"soguktan\", \"yatak\", \"sisme\", \"bez\", \"bezi\", \"bebek bezi\", \"soba\", \n",
    "                    \"hijyen\", \"temizlik\", \"temizlik malzemesi\", \"basortu\", \"hijyen paketi\", \"kar\", \"hipotermi\", \"donmak\", \"yorgan\"]\n",
    "\n",
    "ihtiyaclist = [\"yardım gitmemiş\", \"ihtiyac\", \"ihtiyacı\",\"ihtiyaci\",\"bez\", \"gıda\", \"i̇htiyaç\", \"konserve\", \"çocuk  bezi\", \"maması\", \"orkid\", \"battaniye\", \"çocuk\", \"ilaçları\", \"calpol\", \"dolven\", \"ağrı\", \"kesici\", \"eldiven\", \"bere\", \"atkı\", \"bot\", \"mont\" ,\"çorap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df['isinma'] = df['adres'].str.findall('|'.join(isinma_keywords)).astype(str)\n",
    "df['isinma'] = df['isinma'].str.replace('[','').str.replace(']','')\n",
    "\n",
    "df['barinma'] = df['adres'].str.findall('|'.join(barinma_keywords)).astype(str)\n",
    "df['barinma'] = df['barinma'].str.replace('[','').str.replace(']','')\n",
    "\n",
    "df['yemek'] = df['adres'].str.findall('|'.join(yemek_keywords)).astype(str)\n",
    "df['yemek'] = df['yemek'].str.replace('[','').str.replace(']','')\n",
    "\n",
    "df['su'] = df['adres'].str.findall('|'.join(su_keywords)).astype(str)\n",
    "df['su'] = df['su'].str.replace('[','').str.replace(']','')\n",
    "\n",
    "df['tuvalet'] = df['adres'].str.findall('|'.join(tuvalet_keywords)).astype(str)\n",
    "df['tuvalet'] = df['tuvalet'].str.replace('[','').str.replace(']','')\n",
    "\n",
    "df['giysi'] = df['adres'].str.findall('|'.join(giysi_keywords)).astype(str)\n",
    "df['giysi'] = df['giysi'].str.replace('[','').str.replace(']','')\n",
    "\n",
    "df['yagma'] = df['adres'].str.findall('|'.join(yagma)).astype(str)\n",
    "df['yagma'] = df['yagma'].str.replace('[','').str.replace(']','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find sinma\tbarinma\tyemek su tuvalet giysi yagma any of them not empty\n",
    "qf = df.loc[(df['isinma'] != '') | (df['barinma'] != '') | (df['yemek'] != '') | (df['su'] != '') | (df['tuvalet'] != '') | (df['giysi'] != '') | (df['yagma'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "# rename createdAt as date\n",
    "qf = qf.rename(columns={'createdAt': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date strings to datetime objects\n",
    "qf['date'] = qf['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ'))\n",
    "\n",
    "# Add three hours to each datetime object\n",
    "qf['date'] = qf['date'].apply(lambda x: x + timedelta(hours=3))\n",
    "\n",
    "# Format the datetime objects as desired\n",
    "qf['date'] = qf['date'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort qf by deprem\tGelen\tisinma\tbarinma\tyemek\tsu\ttuvalet\tgiysi yagma\n",
    "qf.sort_values(by=['date','isinma','barinma','yemek','su','tuvalet','giysi','yagma'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = ['isinma','barinma','yemek','su','tuvalet','giysi','yagma', 'deprem', 'Gelen']\n",
    "for col in cleaner:\n",
    "    qf[col] = qf[col].str.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf = qf[qf['giysi'] != 'kar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum word counts in this columns deprem\tGelen\tisinma\tbarinma\tyemek\tsu\ttuvalet\tgiysi\tyagma\n",
    "# word count function on column\n",
    "def word_count(x):\n",
    "    return len(x.split())\n",
    "\n",
    "# word count on each row\n",
    "qf['isinma_count'] = qf['isinma'].apply(word_count)\n",
    "qf['barinma_count'] = qf['barinma'].apply(word_count)\n",
    "qf['yemek_count'] = qf['yemek'].apply(word_count)\n",
    "qf['su_count'] = qf['su'].apply(word_count)\n",
    "qf['tuvalet_count'] = qf['tuvalet'].apply(word_count)\n",
    "qf['giysi_count'] = qf['giysi'].apply(word_count)\n",
    "qf['yagma_count'] = qf['yagma'].apply(word_count)\n",
    "\n",
    "# total\n",
    "qf['total'] = qf['isinma_count'] + qf['barinma_count'] + qf['yemek_count'] + qf['su_count'] + qf['tuvalet_count'] + qf['giysi_count'] + qf['yagma_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd max colwidth\n",
    "pd.set_option('display.max_colwidth', 1)\n",
    "# pd show max rows\n",
    "pd.set_option('display.max_rows', 11)\n",
    "qf.sort_values('total', ascending=False).head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf = qf[qf['total'] > 2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean columns that contains count in them\n",
    "qf = qf.drop(['isinma_count','barinma_count','yemek_count','su_count','tuvalet_count','giysi_count','yagma_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf.to_excel('Yardım_Talepleri.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf.to_excel('İhtiyaclar.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83ec7b85d3a25a6df69dd7180066c262f677b7f1f740a511feb54b0bc22f26f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
